# Attention-is-all-you-need-In-Class-

## ğŸ“ Classroom Attention Monitoring System

A Computer Vision-based system for analyzing student attention in classroom videos using face detection, tracking, and head pose estimation.

This project processes a classroom video, tracks students, evaluates attention behavior, and generates per-student analytics in CSV format.

---

## ğŸš€ Features

- âœ… Face-based student tracking
- âœ… Stable tracking IDs within a video
- âœ… Head poseâ€“based attention detection
- âœ… Optional hand raise detection
- âœ… Rolling smoothing for stable classification
- âœ… Per-student statistics collection
- âœ… Automatic CSV report generation
- âœ… CPU compatible
- âœ… tqdm progress bar support

---

## ğŸ— Project Structure

```
classroom_attention/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ face_detector.py
â”‚ â”‚ â”œâ”€â”€ tracker.py
â”‚ â”‚ â”œâ”€â”€ pose_analyzer.py
â”‚ â”‚ â””â”€â”€ detectors.py (if using YOLO)
â”‚ â”‚
â”‚ â””â”€â”€ pipeline/
â”‚ â””â”€â”€ processor.py
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ output.avi
â”‚ â””â”€â”€ attention_results.csv
â”‚
â”œâ”€â”€ run.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§  System Architecture

```
Video Input
â†“
Face Detection (MediaPipe)
â†“
DeepSORT Tracking
â†“
Head Pose Analysis
â†“
Attention Scoring
â†“
Per-Student Statistics
â†“
CSV Report Generation
```

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the Repository
```
git clone <your-repository-url>
cd classroom_attention
```
### 2ï¸âƒ£ Create Virtual Environment
```
python3 -m venv venv
source venv/bin/activate
```
### 3ï¸âƒ£ Install Dependencies
```pip install -r requirements.txt```

Or manually:

```pip install ultralytics deep-sort-realtime mediapipe tqdm numpy opencv-python```
### â–¶ï¸ Running the Project

Place your classroom video in the root folder as:

```input.mp4```

Run the system:

```python run.py```

### ğŸ“¤ Output Files

After processing completes:
```
outputs/output.avi
outputs/attention_results.csv
```
### ğŸ“Š CSV Output Format

The CSV file contains per-student analytics:
```
Student_ID,
Total_Frames,
Attentive_Frames,
HandRaise_Frames,
Distracted_Frames,
Attention_Percentage
```
#### Example Output
```
2,252,110,114,28,43.65
3,3057,195,2622,240,6.38
```

## ğŸ“ˆ Attention Calculation Logic

For each tracked student:

### +1 â†’ Looking forward

### +1 â†’ Hand raised (if enabled)

### -2 â†’ Using phone (if enabled)

Final attention percentage:

```
(attentive_frames / total_frames) Ã— 100
```

Short-lived tracks are filtered to avoid false student counts.

## âš¡ Performance Notes

- Pose estimation runs every 5 frames (CPU optimization)

- DeepSORT parameters tuned for classroom stability

- Face detection reduces false positives

- Tracking IDs are stable within a single video

---

## ğŸ›  Technologies Used

- Python 3.10

- OpenCV

- MediaPipe

- DeepSORT

- YOLO (optional)

- NumPy

- tqdm

---
ğŸ”® Future Improvements

Real-time webcam version

Web dashboard for visualization

Face recognition for persistent IDs across sessions

FastAPI deployment

Docker containerization

Classroom-level attention analytics dashboard

---

ğŸ“œ License

This project is developed for academic and research purposes.


---

